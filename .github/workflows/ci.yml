name: CI

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

env:
  PROJECT_ID: production-466308
  REGION: europe-west1
  REPOSITORY: aksio
  SERVICE: aksio-backend

permissions:
  pull-requests: write
  contents: write
  id-token: write  # Required for Workload Identity Federation
  
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: true
    steps:
      - uses: actions/checkout@v4
      
      - name: Build docker image and run tests
        env:
          # Django Configuration
          DJANGO_SECRET_KEY: ${{ secrets.DJANGO_SECRET_KEY }}
          DJANGO_DEBUG: True
          DJANGO_SETTINGS_MODULE: aksio.settings.testing
          
          # Database Configuration (local PostgreSQL for tests)
          DATABASE_HOST: localhost
          DATABASE_PORT: 5432
          DATABASE_NAME: test_aksio_db
          DATABASE_USER: postgres
          DATABASE_PASSWORD: postgres
          
          # Redis Configuration
          REDIS_URL: redis://localhost:6379/0
          
          # AI Configuration
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LLM_PROVIDER: openai
          LLM_MODEL: gpt-4
          
          # Google Cloud Configuration (using test bucket)
          GOOGLE_CLOUD_PROJECT: ${{ env.PROJECT_ID }}
          GCS_BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME_TEST }}
          
          # External Services (mocked for tests)
          SCRAPER_SERVICE_URL: http://localhost:8080
          RETRIEVER_SERVICE_URL: http://localhost:8002
          
        run: |
          # Create test environment file
          cat > .env.test <<EOF
          DJANGO_SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}
          DJANGO_SETTINGS_MODULE=aksio.settings.testing
          DATABASE_HOST=db
          DATABASE_PORT=5432
          DATABASE_NAME=test_aksio_db
          DATABASE_USER=aksio_user
          DATABASE_PASSWORD=aksio_password
          REDIS_URL=redis://redis:6379/0
          OPENAI_API_KEY=test-key
          ENABLE_AI_FEATURES=False
          EOF
          
          # Build and run tests using docker-compose
          docker network create aksio_network || true
          docker compose -f docker-compose.yaml down -v
          docker compose -f docker-compose.yaml build backend
          
          # Start services and wait for them to be ready
          docker compose -f docker-compose.yaml up -d db redis
          sleep 10
          
          # Run migrations for all apps
          docker compose -f docker-compose.yaml run --rm \
            -e DJANGO_SETTINGS_MODULE=aksio.settings.testing \
            -e DATABASE_HOST=db \
            -e DATABASE_NAME=test_aksio_db \
            -e DATABASE_USER=aksio_user \
            -e DATABASE_PASSWORD=aksio_password \
            backend python manage.py migrate
          
          # Run tests without parallel execution to avoid issues
          docker compose -f docker-compose.yaml run --rm \
            -e DJANGO_SETTINGS_MODULE=aksio.settings.testing \
            -e DATABASE_HOST=db \
            -e DATABASE_NAME=test_aksio_db \
            -e DATABASE_USER=aksio_user \
            -e DATABASE_PASSWORD=aksio_password \
            -e OPENAI_API_KEY=test-key \
            -e ENABLE_AI_FEATURES=False \
            backend python manage.py test --keepdb
          
          # Clean up
          docker compose -f docker-compose.yaml down -v

  push-image:
    name: Build and Push Docker Image to Artifact Registry
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      id-token: write  # Required for Workload Identity Federation
      
    # Only runs if CI was successful and on main branch
    needs: [build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${REGION}-docker.pkg.dev

      - name: Build and Push Docker image
        run: |
          IMAGE_TAG="${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${SERVICE}:${GITHUB_SHA}"
          IMAGE_LATEST="${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPOSITORY}/${SERVICE}:latest"
          
          # Build the image
          docker build -t ${IMAGE_TAG} -t ${IMAGE_LATEST} .
          
          # Push both tags
          docker push ${IMAGE_TAG}
          docker push ${IMAGE_LATEST}
          
  dependabot:
    name: 'Dependabot'
    # After the E2E and build jobs, if one of them fails, it won't merge the PR.
    needs: [build] 
    runs-on: ubuntu-latest
    # Detect that the PR author is dependabot
    if: ${{ github.actor == 'dependabot[bot]' && github.event_name == 'pull_request'}} 
    steps:
      - name: Enable auto-merge for Dependabot PRs
        # Use Github CLI to merge automatically the PR
        run: gh pr merge --auto --merge "$PR_URL" 
        env:
          PR_URL: ${{github.event.pull_request.html_url}}
          GITHUB_TOKEN: ${{secrets.GITHUB_TOKEN}}
